# Copyright (c) 2018-2019 NVIDIA CORPORATION.  All rights reserved.

@page dwx_integrate_dnn_sample Basic integration of a dnn to driveworks
@tableofcontents

@section dwx_integrate_dnn_description Description

The basic dnn integration sample demonstrates how to take a pretrained nueral network
and run inference with it on the drive in an optimized way.

The sample takes either a live camera input image or an image file and run inference on it with 
the pretrained trt optimized plan file that was givven.

The interpretation of the output of a network depends on the network design. In this sample,
resnet50 is used and expectes one output and one input image blob .

For each new frame from the camera (or for each cycle of run when an image file is loaded), it detects the object calssification,
and visualize the result.

@section dwx_integrate_dnn_running Running the Sample

The integrate dnn sample, `sample_integrate_dnn`, accepts the following optional parameters.

	./sample_integrate_dnn --tensorRT_model=[path/to/TensorRT/model]
							--referenceFileName=[classification_labels_reference_file.txt]
							--data=[path/to/data/directory]
							--usbDeviceID=[integer]
							--usbCamMode=[a|b|integer]
							--imageFile=[path/to/individual/image/file]
							--imagesDir=[path/to/image/dir/to/load]
							--profiling=[1/0]
							--useCamera=[1/0]
							--camera-type=[camera_type]
							--camera-group=[a|b|c|d]
							--camera-index=[0|1|2|3]
    						specify whether to use a USB camera as source.


Where:

    --tensorRT_model=[path/to/TensorRT/model]
        path to TensorRT bin file generated by the tensorRT_optimization tool
	
	--referenceFileName=[classification_labels_reference_file.txt]
		reference file for classification labels.
		Default value: reference_labels.txt
		    
    --data=[path/to/data/directory]
        Specify data directory to search for above files in case absolute paths to files are not provided.
        Default value: data/samples/resnet50/
	
	--useCamera=[1/0]
		Enables/disables usage of usb camera as source
		Default value: 0	
	
    --usbDeviceID=[integer]
        Is the device ID of the camera if a camera source is requested.
        Only applicable if --useCamera=1.
        Default value: 0
            
	--usbCamMode=[a|b|integer]
		Applicable for generic camera only. Specifies a method for selecting capture settings: 
								`a`: choose mode with maximum resolution 
								`b`: choose mode with maximum fps 
								integer number: choose mode by index
		Only applicable if --useCamera=1.								
		Default value: 0
			
	--imageFile=[path/to/individual/image/file]
		ppm image file to proccess in case only once image is requested to run inference on.
		Only applicable if --useCamera=0.
		Default value: ""
	
	--imagesDir=[path/to/image/dir/to/load]
		path to ppm images folder to load for running inference on them.
		Only applicable if --useCamera=0.
		Default value: ""

    --camera-type=[camera] 
            Specifies a supported AR0231 `RCCB` sensor or "usb" for usb camera.
            Only applicable if --useCamera=1.
            Default value on Vibrante: ar0231-rccb-bae-sf3324
            Default value on x86: usb

    --camera-group=[a|b|c|d]
            Specifies the group to which the camera is connected.
            Only applicable if --input-type=camera.
            Default value: a
    
    --camera-index=[0|1|2|3] 
            Indicates the camera index on the given port.
            Default value: 0
    		
	--profiling=[1/0]
		Enables/disables sample profiling
		Default value: 1			
    						
@note This sample loads its DataConditioner parameters from DNN metadata JSON file.
To provide the DNN metadata to the DNN module, place the JSON file in the same
directory as the model file. An example of the DNN metadata file is:

    data/samples/detector/pascal/tensorRT_model.bin.json 

@subsection dwx_integrate_dnn_sample_examples Examples

#### Default usage

     ./sample_integrate_dnn

The images files must be a ppm format. all other images files are not supported.

#### To run the sample on a images located in data/images folder

    ./sample_integrate_dnn --tensorRT_model=resnet50Onnx2TRTx86.bin --data=data/resnet50/ --imagesDir=data/resnet50/images/

#### To run the sample on a usb camera images

    ./sample_integrate_dnn --tensorRT_model=resnet50Onnx2TRTx86.bin --data=data/resnet50/ --useCamera=1

@section dwx_integrate_dnn_sample_output Output

The sample creates a window, displays the image stream (either from a camera or from an image file), 
and displays the classification results for the objects in the picture.
a red bounding box can be selected with the mouse to run classification on part of the image.

